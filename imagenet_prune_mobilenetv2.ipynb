{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pruner import l1normPruner\n",
    "import pruner\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from models import *\n",
    "import torch.optim as optim\n",
    "from os.path import join\n",
    "import json\n",
    "\n",
    "from mythop import clever_format, profile\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotmap import DotMap\n",
    "\n",
    "\n",
    "# python prune.py --arch MobileNetV2 --pruner l1normpruner --pruneratio 0.6\n",
    "\n",
    "args = DotMap()\n",
    "\n",
    "args.dataset = 'imagenet'\n",
    "args.workers=8\n",
    "args.batch_size = 16\n",
    "args.test_batch_size = 8\n",
    "args.epochs = 10\n",
    "\n",
    "args.start_epoch = 0\n",
    "args.finetunelr = 0.01\n",
    "\n",
    "args.momentum = 0.9\n",
    "args.weight_decay = 1e-4\n",
    "\n",
    "args.resume = ''\n",
    "args.no_cuda=False\n",
    "args.seed=1\n",
    "\n",
    "args.save = 'checkpoints'\n",
    "args.arch = 'MobileNetV2'\n",
    "args.pruner = 'l1normPruner'\n",
    "args.pruneratio = 0.6\n",
    "args.sr = True\n",
    "\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "savepath = os.path.join(args.save, args.arch, 'sr' if args.sr else 'nosr')\n",
    "args.savepath = savepath\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "\n",
    "args.data = '/home/hongky/datasets/imagenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "traindir = os.path.join(args.data, 'train')\n",
    "valdir = os.path.join(args.data, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True, sampler=None)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=args.test_batch_size, shuffle=False,\n",
    "    num_workers=args.workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from models import *\n",
    "\n",
    "torch_mobilenetv2 = torchvision.models.mobilenet.mobilenet_v2(pretrained=True)\n",
    "\n",
    "def clone_mobilenet():\n",
    "    mobilenet2 = eval('MobileNetV2')(n_class=1000, input_size=224)\n",
    "\n",
    "\n",
    "    # classifier\n",
    "    mobilenet2.classifier = torch_mobilenetv2.classifier \n",
    "\n",
    "    # features 0\n",
    "    mobilenet2.features[0].convbn.conv = torch_mobilenetv2.features[0][0]\n",
    "    mobilenet2.features[0].convbn.bn = torch_mobilenetv2.features[0][1]\n",
    "    mobilenet2.features[0].convbn.relu = torch_mobilenetv2.features[0][2]\n",
    "\n",
    "    # features 18\n",
    "    mobilenet2.features[18].convbn.conv = torch_mobilenetv2.features[18][0]\n",
    "    mobilenet2.features[18].convbn.bn = torch_mobilenetv2.features[18][1]\n",
    "    mobilenet2.features[18].convbn.relu = torch_mobilenetv2.features[18][2]\n",
    "\n",
    "    # feature 1\n",
    "    mobilenet2.features[1].conv.dw_conv = torch_mobilenetv2.features[1].conv[0][0]\n",
    "    mobilenet2.features[1].conv.dw_bn = torch_mobilenetv2.features[1].conv[0][1]\n",
    "    mobilenet2.features[1].conv.dw_relu = torch_mobilenetv2.features[1].conv[0][2]\n",
    "    mobilenet2.features[1].conv.project_conv = torch_mobilenetv2.features[1].conv[1]\n",
    "    mobilenet2.features[1].conv.project_bn = torch_mobilenetv2.features[1].conv[2]\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(2, 18):\n",
    "        mobilenet2.features[i].conv.expand_conv = torch_mobilenetv2.features[i].conv[0][0]\n",
    "        mobilenet2.features[i].conv.expand_bn = torch_mobilenetv2.features[i].conv[0][1]\n",
    "        mobilenet2.features[i].conv.expand_relu = torch_mobilenetv2.features[i].conv[0][2]\n",
    "\n",
    "        mobilenet2.features[i].conv.dw_conv = torch_mobilenetv2.features[i].conv[1][0]\n",
    "        mobilenet2.features[i].conv.dw_bn = torch_mobilenetv2.features[i].conv[1][1]\n",
    "        mobilenet2.features[i].conv.dw_relu = torch_mobilenetv2.features[i].conv[1][2]\n",
    "\n",
    "        mobilenet2.features[i].conv.project_conv = torch_mobilenetv2.features[i].conv[2]\n",
    "        mobilenet2.features[i].conv.project_bn = torch_mobilenetv2.features[i].conv[3]\n",
    "\n",
    "    return mobilenet2\n",
    "\n",
    "model = clone_mobilenet()\n",
    "newmodel = clone_mobilenet()\n",
    "\n",
    "\n",
    "if args.cuda:\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "    newmodel = nn.DataParallel(newmodel).cuda()\n",
    "# if args.cuda:\n",
    "#     model = model.cuda()\n",
    "#     newmodel = newmodel.cuda()\n",
    "model.eval()\n",
    "newmodel.eval()\n",
    "best_prec1 = -1\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.finetunelr, momentum=args.momentum, weight_decay=args.weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from models import MobileNetV2, InvertedResidual, sepconv_bn, conv_bn_relu, ShuffleV2Block, Bottleneck\n",
    "from pruner.Block import *\n",
    "\n",
    "\n",
    "\n",
    "class BasePruner:\n",
    "    def __init__(self, model, newmodel, testset, trainset, optimizer, args):\n",
    "        self.model = model\n",
    "        self.newmodel = newmodel\n",
    "        self.testset = testset\n",
    "        self.trainset = trainset\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3, threshold=1e-2)\n",
    "        self.args = args\n",
    "        self.blocks = []\n",
    "\n",
    "    def prune(self):\n",
    "        self.blocks = []\n",
    "        for midx, (name, module) in enumerate(self.model.named_modules()):\n",
    "            idx = len(self.blocks)\n",
    "            if isinstance(module, InvertedResidual):\n",
    "                self.blocks.append(InverRes(name, idx, idx - 1, idx + 1, list(module.state_dict().values())))\n",
    "            if isinstance(module, conv_bn_relu):\n",
    "                # print(module)\n",
    "                # for k, v in module.state_dict().items():\n",
    "                #     print(k, v.shape)\n",
    "                self.blocks.append(CB(name, idx, idx - 1, idx + 1, list(module.state_dict().values())))\n",
    "            if isinstance(module, nn.Linear):\n",
    "                self.blocks.append(FC(name, idx, idx - 1, idx + 1, list(module.state_dict().values())))\n",
    "            if isinstance(module, ShuffleV2Block):\n",
    "                self.blocks.append(ShuffleLayer(name, idx, idx - 1, idx + 1, list(module.state_dict().values())))\n",
    "            if isinstance(module, Bottleneck):\n",
    "                self.blocks.append(ResBottle(name, idx, idx - 1, idx + 1, list(module.state_dict().values())))\n",
    "        # special blocks\n",
    "        # for b in self.blocks:\n",
    "            # if b.layername == 'features.18':\n",
    "            #     b.keepoutput = True\n",
    "            #     b.bnscale = None\n",
    "\n",
    "    def test(self, newmodel=True, ckpt=None, cal_bn=False):\n",
    "        if newmodel:\n",
    "            model = self.newmodel\n",
    "        else:\n",
    "            model = self.model\n",
    "        if ckpt:\n",
    "            model.load_state_dict(ckpt)\n",
    "        if cal_bn:\n",
    "            model.train()\n",
    "            # for idx,(data, target) in enumerate(tqdm(self.trainset, total=len(self.trainset))):\n",
    "            for idx, (data, target) in enumerate(self.trainset):\n",
    "                #data, target = data.cuda(), target.cuda()\n",
    "                target = target.cuda()\n",
    "                if idx == 100:\n",
    "                    break\n",
    "                with torch.no_grad():\n",
    "                    _ = model(data)\n",
    "            # print(\"calibrate bn done.\")\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        # for data, target in tqdm(self.testset, total=len(self.testset)):\n",
    "        for idx, (data, target) in tqdm(self.testset, total=len(self.testset)): #enumerate(self.testset):\n",
    "            #data, target = data.cuda(), target.cuda()\n",
    "            target = target.cuda()\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item()  # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        test_loss /= len(self.testset.dataset)\n",
    "        return correct.item() / float(len(self.testset.dataset))\n",
    "\n",
    "    def train(self):\n",
    "        self.newmodel.train()\n",
    "        avg_loss = 0.\n",
    "        train_acc = 0.\n",
    "        for batch_idx, (data, target) in tqdm(enumerate(self.trainset), total=len(self.trainset)):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.newmodel(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            avg_loss += loss.item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def finetune(self):\n",
    "        best_prec1 = 0\n",
    "        for epoch in range(1):\n",
    "            self.train()\n",
    "            prec1 = self.test()\n",
    "            self.scheduler.step(prec1)\n",
    "            lr_current = self.optimizer.param_groups[0]['lr']\n",
    "            print(\"currnt lr:{},current prec:{}\".format(lr_current, prec1))\n",
    "            is_best = prec1 > best_prec1\n",
    "            best_prec1 = max(prec1, best_prec1)\n",
    "            if is_best:\n",
    "                ckptfile = os.path.join(self.args.savepath, 'ft_model_best.pth.tar')\n",
    "            else:\n",
    "                ckptfile = os.path.join(self.args.savepath, 'ft_checkpoint.pth.tar')\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': self.newmodel.state_dict(),\n",
    "                'best_prec1': best_prec1,\n",
    "                'optimizer': self.optimizer.state_dict(),\n",
    "            }, ckptfile)\n",
    "        return best_prec1\n",
    "\n",
    "    def clone_model(self):\n",
    "        blockidx = 0\n",
    "        for name, m0 in self.newmodel.named_modules():\n",
    "            if type(m0) not in [InvertedResidual,conv_bn_relu,nn.Linear,Bottleneck,ShuffleV2Block]:\n",
    "                continue\n",
    "            block = self.blocks[blockidx]\n",
    "            curstatedict = block.statedict\n",
    "            if blockidx == 0:\n",
    "                inputmask = torch.arange(block.inputchannel)\n",
    "            # print('name:', name, 'block.layername:', block.layername)\n",
    "            assert name == block.layername\n",
    "            if isinstance(block, CB):\n",
    "                # conv(1weight)->bn(4weight)->relu\n",
    "                assert len(curstatedict) == (1 + 4)\n",
    "                block.clone2module(m0, inputmask)\n",
    "                inputmask = block.prunemask\n",
    "            if isinstance(block, InverRes):\n",
    "                # dw->project or expand->dw->project\n",
    "                assert len(curstatedict) in (10, 15)\n",
    "                block.clone2module(m0, inputmask)\n",
    "                inputmask = torch.arange(block.outputchannel)\n",
    "            if isinstance(block, FC):\n",
    "                block.clone2module(m0,inputmask)\n",
    "            if isinstance(block, ResBottle):\n",
    "                # dw->project or expand->dw->project\n",
    "                assert len(curstatedict) in (15, 20)\n",
    "                block.clone2module(m0, inputmask)\n",
    "                inputmask = torch.arange(block.outputchannel)\n",
    "            if isinstance(block, ShuffleLayer):\n",
    "                if block.bnscale is not None:\n",
    "                    block.clone2module(m0, inputmask)\n",
    "                    inputmask = torch.arange((block.inputchannel + block.outputchannel) / 2)\n",
    "                    if block.layername == 'features.3': # for 'features.4' stride=2, no pruning\n",
    "                        inputmask = torch.arange(block.inputchannel + block.outputchannel)\n",
    "                    if block.layername == 'features.15': # for 'conv_last' inputchannel=464\n",
    "                        inputmask = torch.arange(block.inputchannel + block.outputchannel)\n",
    "            blockidx += 1\n",
    "            if blockidx > (len(self.blocks) - 1): break\n",
    "        \n",
    "        for name0, m0 in self.newmodel.named_modules():\n",
    "            if name0 == 'first_conv.0':\n",
    "                for name1, m1 in self.model.named_modules():\n",
    "                    if name1 == 'first_conv.0':\n",
    "                        break\n",
    "                m0.weight.data = m1.weight.data\n",
    "                break\n",
    "        \n",
    "        for name0, m0 in self.newmodel.named_modules():\n",
    "            if name0 == 'first_conv.1':\n",
    "                for name1, m1 in self.model.named_modules():\n",
    "                    if name1 == 'first_conv.1':\n",
    "                        break\n",
    "                m0.weight.data = m1.weight.data\n",
    "                m0.bias.data = m1.bias.data\n",
    "                m0.running_mean.data = m1.running_mean.data\n",
    "                m0.running_var.data = m1.running_var.data\n",
    "                break\n",
    "\n",
    "    def get_flops(self, model):\n",
    "        from thop import clever_format, profile\n",
    "        input = torch.randn(1, 3, 32, 32).cuda()\n",
    "        flops, params = profile(model, inputs=(input,), verbose=False)\n",
    "        return flops, params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class l1normPruner(BasePruner):\n",
    "    def __init__(self, model, newmodel, testset, trainset, optimizer, args, pruneratio=0.1):\n",
    "        super().__init__(model, newmodel, testset, trainset, optimizer, args)\n",
    "        self.pruneratio = pruneratio\n",
    "\n",
    "    def prune(self):\n",
    "        #super().prune()\n",
    "        self.blocks = []\n",
    "        for midx, (name, module) in enumerate(self.model.named_modules()):\n",
    "            idx = len(self.blocks)\n",
    "            if isinstance(module, InvertedResidual):\n",
    "                self.blocks.append(InverRes(name, idx, idx - 1, idx + 1, list(module.state_dict().values())))\n",
    "            if isinstance(module, conv_bn_relu):\n",
    "                # print(module)\n",
    "                # for k, v in module.state_dict().items():\n",
    "                #     print(k, v.shape)\n",
    "                self.blocks.append(CB(name, idx, idx - 1, idx + 1, list(module.state_dict().values())))\n",
    "            if isinstance(module, nn.Linear):\n",
    "                self.blocks.append(FC(name, idx, idx - 1, idx + 1, list(module.state_dict().values())))\n",
    "            if isinstance(module, ShuffleV2Block):\n",
    "                self.blocks.append(ShuffleLayer(name, idx, idx - 1, idx + 1, list(module.state_dict().values())))\n",
    "            if isinstance(module, Bottleneck):\n",
    "                self.blocks.append(ResBottle(name, idx, idx - 1, idx + 1, list(module.state_dict().values())))\n",
    "                \n",
    "        for b in self.blocks:\n",
    "            if isinstance(b, CB):\n",
    "                pruneweight = torch.sum(torch.abs(b.statedict[0]), dim=(1, 2, 3))\n",
    "                numkeep = int(pruneweight.shape[0] * (1 - self.pruneratio))\n",
    "                _ascend = torch.argsort(pruneweight)\n",
    "                _descend = torch.flip(_ascend, (0,))[:numkeep]\n",
    "                mask = torch.zeros_like(pruneweight).long()\n",
    "                mask[_descend] = 1\n",
    "                b.prunemask = torch.where(mask == 1)[0]\n",
    "            if isinstance(b, InverRes):\n",
    "                if b.numlayer == 3:\n",
    "                    pruneweight = torch.sum(torch.abs(b.statedict[0]), dim=(1, 2, 3))\n",
    "                    numkeep = int(pruneweight.shape[0] * (1 - self.pruneratio))\n",
    "                    _ascend = torch.argsort(pruneweight)\n",
    "                    _descend = torch.flip(_ascend, (0,))[:numkeep]\n",
    "                    mask = torch.zeros_like(pruneweight).long()\n",
    "                    mask[_descend] = 1\n",
    "                    b.prunemask = torch.where(mask == 1)[0]\n",
    "        self.clone_model()\n",
    "        print(\"l1 norm Pruner done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch,test_width=1.0,recal=False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    model.apply(lambda m: setattr(m, 'width_mult',test_width))\n",
    "            \n",
    "    model.eval()\n",
    "    for data, target in tqdm(test_loader, total=len(test_loader)):\n",
    "        if args.cuda:\n",
    "            target = target.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target, size_average=False).item()  # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nEpoch: {} Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(epoch,\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct.item() / float(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [11:45<00:00,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0 Test set: Average loss: 1.1477, Accuracy: 35939/50000 (71.9%)\n",
      "\n",
      "0.71878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(test(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: module.features.0 block.layername: module.features.0\n",
      "name: module.features.1 block.layername: module.features.1\n",
      "name: module.features.2 block.layername: module.features.2\n",
      "name: module.features.3 block.layername: module.features.3\n",
      "name: module.features.4 block.layername: module.features.4\n",
      "name: module.features.5 block.layername: module.features.5\n",
      "name: module.features.6 block.layername: module.features.6\n",
      "name: module.features.7 block.layername: module.features.7\n",
      "name: module.features.8 block.layername: module.features.8\n",
      "name: module.features.9 block.layername: module.features.9\n",
      "name: module.features.10 block.layername: module.features.10\n",
      "name: module.features.11 block.layername: module.features.11\n",
      "name: module.features.12 block.layername: module.features.12\n",
      "name: module.features.13 block.layername: module.features.13\n",
      "name: module.features.14 block.layername: module.features.14\n",
      "name: module.features.15 block.layername: module.features.15\n",
      "name: module.features.16 block.layername: module.features.16\n",
      "name: module.features.17 block.layername: module.features.17\n",
      "name: module.features.18 block.layername: module.features.18\n",
      "name: module.classifier.1 block.layername: module.classifier.1\n",
      "l1 norm Pruner done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original performance:0.00098\n"
     ]
    }
   ],
   "source": [
    "if args.pruner == 'l1normPruner':\n",
    "    kwargs = {'pruneratio': args.pruneratio}\n",
    "elif args.pruner == 'SlimmingPruner':\n",
    "    kwargs = {'pruneratio': args.pruneratio}\n",
    "elif args.pruner == 'AutoSlimPruner':\n",
    "    kwargs = {'prunestep': 16, 'constrain': 200e6}\n",
    "\n",
    "pruner_object = l1normPruner(\n",
    "            model=model, \n",
    "            newmodel=newmodel, \n",
    "            testset=test_loader, \n",
    "            trainset=train_loader,\n",
    "            optimizer=optimizer, args=args, **kwargs)\n",
    "pruner_object.prune()\n",
    "##---------count op\n",
    "# input = torch.randn(1, 3, 32, 32).cuda()\n",
    "# flops, params = profile(model, inputs=(input,), verbose=False)\n",
    "# flops, params = clever_format([flops, params], \"%.3f\")\n",
    "# flopsnew, paramsnew = profile(newmodel, inputs=(input,), verbose=False)\n",
    "# flopsnew, paramsnew = clever_format([flopsnew, paramsnew], \"%.3f\")\n",
    "# print(\"flops:{}->{}, params: {}->{}\".format(flops, flopsnew, params, paramsnew))\n",
    "\n",
    "\n",
    "accold = pruner_object.test(newmodel=False, cal_bn=False)\n",
    "print(\"original performance:{}\".format(accold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "accpruned = pruner_object.test(newmodel=True)\n",
    "print(\"pruned performance:{}\".format(accpruned))\n",
    "\n",
    "accfinetune = pruner_object.finetune()\n",
    "print(\"finetuned:{}\".format(accfinetune))\n",
    "\n",
    "with open(join(savepath, '{}.json'.format(args.pruneratio)), 'w') as f:\n",
    "    json.dump({\n",
    "        'accuracy_original': accold,\n",
    "        'accuracy_pruned': accpruned,\n",
    "        'accuracy_finetune': accfinetune,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_tutorial",
   "language": "python",
   "name": "tf_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
