{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from models import *\n",
    "from tqdm import tqdm\n",
    "from models.slimmableops import bn_calibration_init\n",
    "import USconfig as FLAGS\n",
    "import random\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotmap import DotMap\n",
    "\n",
    "args = DotMap()\n",
    "\n",
    "args.dataset = 'imagenet'\n",
    "args.batch_size=32\n",
    "args.workers=8\n",
    "args.test_batch_size=4\n",
    "args.epochs = 40\n",
    "args.start_epoch=0\n",
    "args.lr = 0.2\n",
    "args.momentum=0.9\n",
    "args.weight_decay=1e-4\n",
    "args.resume=''\n",
    "args.no_cuda=False\n",
    "args.seed=1\n",
    "args.save='checkpoints_mobilenetv2_imagenet'\n",
    "args.arch='MobileNetV2'\n",
    "args.sr=True\n",
    "args.s=0.0001\n",
    "args.test=True\n",
    "\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "savepath = os.path.join(args.save, args.arch, 'sr' if args.sr else 'nosr')\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "args.data = '/home/hongky/datasets/imagenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Data loading code\n",
    "traindir = os.path.join(args.data, 'train')\n",
    "valdir = os.path.join(args.data, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True, sampler=None)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=args.test_batch_size, shuffle=False,\n",
    "    num_workers=args.workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done eval model: MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): conv_bn_relu(\n",
      "      (convbn): Sequential(\n",
      "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (dw_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (dw_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (dw_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (dw_bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (dw_bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (dw_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (dw_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "        (dw_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (dw_bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (dw_bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (dw_bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (dw_bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (dw_bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (dw_bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "        (dw_bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (dw_bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (dw_bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (expand_conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (expand_bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (expand_relu): ReLU6(inplace=True)\n",
      "        (dw_conv): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (dw_bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dw_relu): ReLU6(inplace=True)\n",
      "        (project_conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (project_bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): conv_bn_relu(\n",
      "      (convbn): Sequential(\n",
      "        (conv): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from models import *\n",
    "\n",
    "torch_mobilenetv2 = torchvision.models.mobilenet.mobilenet_v2(pretrained=True)\n",
    "\n",
    "mobilenet2 = eval('MobileNetV2')(n_class=1000, input_size=224)\n",
    "\n",
    "\n",
    "# classifier\n",
    "mobilenet2.classifier = torch_mobilenetv2.classifier \n",
    "\n",
    "# features 0\n",
    "mobilenet2.features[0].convbn.conv = torch_mobilenetv2.features[0][0]\n",
    "mobilenet2.features[0].convbn.bn = torch_mobilenetv2.features[0][1]\n",
    "mobilenet2.features[0].convbn.relu = torch_mobilenetv2.features[0][2]\n",
    "\n",
    "# features 18\n",
    "mobilenet2.features[18].convbn.conv = torch_mobilenetv2.features[18][0]\n",
    "mobilenet2.features[18].convbn.bn = torch_mobilenetv2.features[18][1]\n",
    "mobilenet2.features[18].convbn.relu = torch_mobilenetv2.features[18][2]\n",
    "\n",
    "# feature 1\n",
    "mobilenet2.features[1].conv.dw_conv = torch_mobilenetv2.features[1].conv[0][0]\n",
    "mobilenet2.features[1].conv.dw_bn = torch_mobilenetv2.features[1].conv[0][1]\n",
    "mobilenet2.features[1].conv.dw_relu = torch_mobilenetv2.features[1].conv[0][2]\n",
    "mobilenet2.features[1].conv.project_conv = torch_mobilenetv2.features[1].conv[1]\n",
    "mobilenet2.features[1].conv.project_bn = torch_mobilenetv2.features[1].conv[2]\n",
    "\n",
    "\n",
    "        \n",
    "for i in range(2, 18):\n",
    "    mobilenet2.features[i].conv.expand_conv = torch_mobilenetv2.features[i].conv[0][0]\n",
    "    mobilenet2.features[i].conv.expand_bn = torch_mobilenetv2.features[i].conv[0][1]\n",
    "    mobilenet2.features[i].conv.expand_relu = torch_mobilenetv2.features[i].conv[0][2]\n",
    "    \n",
    "    mobilenet2.features[i].conv.dw_conv = torch_mobilenetv2.features[i].conv[1][0]\n",
    "    mobilenet2.features[i].conv.dw_bn = torch_mobilenetv2.features[i].conv[1][1]\n",
    "    mobilenet2.features[i].conv.dw_relu = torch_mobilenetv2.features[i].conv[1][2]\n",
    "    \n",
    "    mobilenet2.features[i].conv.project_conv = torch_mobilenetv2.features[i].conv[2]\n",
    "    mobilenet2.features[i].conv.project_bn = torch_mobilenetv2.features[i].conv[3]\n",
    "\n",
    "\n",
    "model = mobilenet2\n",
    "\n",
    "print('Done eval model:', model)\n",
    "\n",
    "\n",
    "# state_dict = load_state_dict_from_url(model_urls['mobilenet_v2'],\n",
    "#                                       progress=True)\n",
    "# model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args.cuda:\n",
    "#     model.cuda()\n",
    "model = nn.DataParallel(model).cuda()\n",
    "best_prec1 = -1\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def updateBN():\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.grad.data.add_(args.s * torch.sign(m.weight.data))  # L1\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    train_acc = 0.\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        if args.cuda:\n",
    "            target = target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        avg_loss += loss.item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        loss.backward()\n",
    "        if args.sr:\n",
    "            updateBN()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "\n",
    "def test(epoch,test_width=1.0,recal=False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    model.apply(lambda m: setattr(m, 'width_mult',test_width))\n",
    "    if recal:\n",
    "        model.apply(bn_calibration_init)\n",
    "        model.train()\n",
    "        for idx,(data, target) in enumerate(tqdm(train_loader, total=len(train_loader))):\n",
    "            if idx==FLAGS.recal_batch:\n",
    "                break\n",
    "            if args.cuda:\n",
    "                target = target.cuda()\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "            del output\n",
    "            \n",
    "    model.eval()\n",
    "    for data, target in tqdm(test_loader, total=len(test_loader)):\n",
    "        if args.cuda:\n",
    "            target = target.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target, size_average=False).item()  # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nEpoch: {} Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(epoch,\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct.item() / float(len(test_loader.dataset))\n",
    "\n",
    "def export2normal():\n",
    "    newmodel=MobileNetV2()\n",
    "    from collections import OrderedDict\n",
    "    statedic=[]\n",
    "    for k2,v in model.state_dict().items():\n",
    "        if 'running' in k2 or 'num_batches_tracked' in k2:\n",
    "            continue\n",
    "        statedic.append(v)\n",
    "    names=[]\n",
    "    for k1,v1 in newmodel.state_dict().items():\n",
    "        if 'running' in k1 or 'num_batches_tracked' in k1:\n",
    "            continue\n",
    "        names.append(k1)\n",
    "    newdic=OrderedDict(zip(names,statedic))\n",
    "    newmodel.load_state_dict(newdic,strict=False)\n",
    "    torch.save(newmodel.state_dict(),os.path.join(savepath,'trans.pth'))\n",
    "    print(\"save transferred ckpt at {}\".format(os.path.join(savepath,'trans.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12500 [00:00<?, ?it/s]/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "100%|██████████| 12500/12500 [20:17<00:00, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0 Test set: Average loss: 1.1477, Accuracy: 35939/50000 (71.9%)\n",
      "\n",
      "Test accuracy 0.71878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy {}\".format(test(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 936/40037 [07:16<4:17:40,  2.53it/s]/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████| 40037/40037 [4:17:24<00:00,  2.59it/s]  \n",
      "  0%|          | 0/12500 [00:00<?, ?it/s]/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "100%|██████████| 12500/12500 [19:10<00:00, 10.87it/s]\n",
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0 Test set: Average loss: 6.9245, Accuracy: 50/50000 (0.1%)\n",
      "\n",
      "currnt lr:0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3056/40037 [19:34<3:53:41,  2.64it/s]/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      " 18%|█▊        | 7194/40037 [45:58<3:29:55,  2.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f910847b0794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-81d07b7a42a0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mupdateBN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf_tutorial/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf_tutorial/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_prec1 = 0. if best_prec1 == -1 else best_prec1\n",
    "scheduler=optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=args.epochs,eta_min=0)\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    train()\n",
    "    prec1 = test(epoch=epoch)\n",
    "    scheduler.step(epoch)\n",
    "    lr_current = optimizer.param_groups[0]['lr']\n",
    "    print(\"currnt lr:{}\".format(lr_current))\n",
    "    is_best = prec1 > best_prec1\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "    if is_best:\n",
    "        ckptfile = os.path.join(savepath, 'model_best.pth.tar')\n",
    "    else:\n",
    "        ckptfile = os.path.join(savepath, 'checkpoint.pth.tar')\n",
    "        \n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_prec1,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, ckptfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:06<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0 Test set: Average loss: 0.2790, Accuracy: 9188/10000 (91.9%)\n",
      "\n",
      "Test accuracy 0.9188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if args.arch=='USMobileNetV2':\n",
    "    export2normal()\n",
    "    res_acc=[1.0]*len(FLAGS.width_mult_list)\n",
    "    for idx,width in enumerate(FLAGS.width_mult_list):\n",
    "        acc=test(width,recal=True)\n",
    "        res_acc[idx]=acc\n",
    "        print(\"Test accuracy for width {} is {}\".format(width,acc))\n",
    "else:\n",
    "    print(\"Test accuracy {}\".format(test(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/MobileNetV2/sr/checkpoint.pth.tar\n"
     ]
    }
   ],
   "source": [
    "print(ckptfile)\n",
    "torch.save({\n",
    "    'epoch': epoch + 1,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'best_prec1': best_prec1,\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "}, ckptfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.json  0.4.json  0.6.json  checkpoint.pth.tar  model_best.pth.tar\r\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/MobileNetV2/sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_tutorial",
   "language": "python",
   "name": "tf_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
